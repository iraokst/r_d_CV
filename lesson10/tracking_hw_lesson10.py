# -*- coding: utf-8 -*-
"""Tracking_HW_Lesson10

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n-VMCRqxjAPMkV7b2Ludk0WJsbYrMinD

# Load dataset from Kaggle

This script demonstrate the block matching tracking approach.

You can find the dataset here:
    https://www.kaggle.com/soumikrakshit/udacity-car-dataset-crowdai
"""

!pip install kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d soumikrakshit/udacity-car-dataset-crowdai

!unzip -q udacity-car-dataset-crowdai.zip -d/content

import os
import cv2
import numpy as np
from matplotlib import pyplot as plt
from moviepy.editor import *

# directory for wrighting
# os.makedirs('/content/tracking')
# directory with dataset
folder = '/content/object-detection-crowdai'

"""# KCF"""

# Load the dataset
frames = os.listdir(folder)

boxes = []

# Sort (alphabetically) to ensure temporal consecutiveness
frames.sort()
idx = frames.index('1479498486471453396.jpg')

# Let's assume the detector has detected a vehicle
x1, y1 = 885, 490
x2, y2 = 1240, 780

width = x2 - x1
height = y2 - y1

# Limit the search to a certain vicinity (since the cars can only move that fast)
search = 50

# Set up tracker
tracker = cv2.TrackerKCF_create()

# Genrate tracking template
img = cv2.imread(os.path.join(folder, frames[idx]))
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Initialize tracker
bbox = (x1, y1, width, height)
ok = tracker.init(img, bbox)

film = []
# Tracking loop
for ii in range(idx, idx + search):
    img = cv2.imread(os.path.join(folder, frames[ii]))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    
        
    ok, bbox = tracker.update(img)
          
    # Show the tracker working
    x1, y1 = int(bbox[0]), int(bbox[1])
    width, height = int(bbox[2]), int(bbox[3])
    cv2.rectangle(img, (x1, y1), (x1+width, y1+height), (0, 255, 0), 2)
    film.append(img)

film = np.array(film)
height, width = film.shape[1:3]

fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
out = cv2.VideoWriter()
out_path = '/content/tracking/openv_cv_tracking_'
output_file_name = out_path +'KCF'+'.mp4' 
fps_of_video = 6

out.open(output_file_name, fourcc, fps_of_video , (width, height), True)

for i in range(film.shape[0]):
    out.write((film[i]))

out.release()

"""# KCF Result"""

path=output_file_name
name_tracking = path.split('/')[-1].split('.')[0]
print(f'Tracker - {name_tracking}')

clip=VideoFileClip(path) 
clip.ipython_display(width=640, maxduration = 40)

"""#CSRT"""

# Load the dataset
frames = os.listdir(folder)

boxes = []

# Sort (alphabetically) to ensure temporal consecutiveness
frames.sort()
idx = frames.index('1479498486471453396.jpg')

# Let's assume the detector has detected a vehicle
x1, y1 = 885, 490
x2, y2 = 1240, 780

width = x2 - x1
height = y2 - y1

# Limit the search to a certain vicinity (since the cars can only move that fast)
search = 50

# Set up tracker
tracker = cv2.TrackerCSRT_create()

# Genrate tracking template
img = cv2.imread(os.path.join(folder, frames[idx]))
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Initialize tracker
bbox = (x1, y1, width, height)
ok = tracker.init(img, bbox)

film = []
# Tracking loop
for ii in range(idx, idx + search):
    img = cv2.imread(os.path.join(folder, frames[ii]))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    
        
    ok, bbox = tracker.update(img)
          
    # Show the tracker working
    x1, y1 = int(bbox[0]), int(bbox[1])
    width, height = int(bbox[2]), int(bbox[3])
    cv2.rectangle(img, (x1, y1), (x1+width, y1+height), (0, 255, 0), 2)
    film.append(img)

film = np.array(film)
height, width = film.shape[1:3]

fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
out = cv2.VideoWriter()
out_path = '/content/tracking/openv_cv_tracking_'
output_file_name = out_path +'CSRT'+'.mp4' 
fps_of_video = 6

out.open(output_file_name, fourcc, fps_of_video , (width, height), True)

for i in range(film.shape[0]):
    out.write((film[i]))

out.release()

"""# CSRT Result"""

path=output_file_name
name_tracking = path.split('/')[-1].split('.')[0]
print(f'Tracker - {name_tracking}')

clip=VideoFileClip(path) 
clip.ipython_display(width=640, maxduration = 40)

"""# MIL"""

# Load the dataset
frames = os.listdir(folder)

boxes = []

# Sort (alphabetically) to ensure temporal consecutiveness
frames.sort()
idx = frames.index('1479498486471453396.jpg')

# Let's assume the detector has detected a vehicle
x1, y1 = 885, 490
x2, y2 = 1240, 780

width = x2 - x1
height = y2 - y1

# Limit the search to a certain vicinity (since the cars can only move that fast)
search = 50

# Set up tracker
tracker = cv2.TrackerMIL_create()

# Genrate tracking template
img = cv2.imread(os.path.join(folder, frames[idx]))
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Initialize tracker
bbox = (x1, y1, width, height)
ok = tracker.init(img, bbox)

film = []
# Tracking loop
for ii in range(idx, idx + search):
    img = cv2.imread(os.path.join(folder, frames[ii]))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    
        
    ok, bbox = tracker.update(img)
          
    # Show the tracker working
    x1, y1 = int(bbox[0]), int(bbox[1])
    width, height = int(bbox[2]), int(bbox[3])
    cv2.rectangle(img, (x1, y1), (x1+width, y1+height), (0, 255, 0), 2)
    film.append(img)

film = np.array(film)
height, width = film.shape[1:3]

fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
out = cv2.VideoWriter()
out_path = '/content/tracking/openv_cv_tracking_'
output_file_name = out_path +'MIL'+'.mp4' 
fps_of_video = 6

out.open(output_file_name, fourcc, fps_of_video , (width, height), True)

for i in range(film.shape[0]):
    out.write((film[i]))

out.release()

"""# MIL Result"""

path=output_file_name
name_tracking = path.split('/')[-1].split('.')[0]
print(f'Tracker - {name_tracking}')

clip=VideoFileClip(path) 
clip.ipython_display(width=640, maxduration = 40)

"""Наилучший результат показывает MIL."""

